**Author:** Yaling Cao

**Student ID:** 23002370

## Motivation:

Inspired by the potential of leveraging TED Talks videos for educational and research purposes, I embarked on a project to collect and process TED videos. The goal is to transform video content into text and use advanced models to generate new, insightful video content related to TED Talks. This project aims to enhance the accessibility and usability of TED Talks by converting them into structured text data, which can be further analyzed and used to generate new content.

## Create Dataset：

To begin, I collected various TED Talks videos to create a comprehensive dataset. The videos were sourced from the official TED website and other reliable platforms.

**Data Collection Site URL:https:** //www.youtube.com/results?search_query=ted

**Datasets:https:** //www.office.com/onedrive

## Try Vosk for Transcription：

With the dataset ready, the next step was to transcribe the video content into text. I utilized the Vosk speech recognition toolkit, which offers robust and accurate transcription capabilities.

**VOSK URL:** https://alphacephei.com/vosk/ and https://github.com/alphacep/vosk-api

This process converted all video audio to text, creating a textual dataset from TED Talks.

## Adjusting and generating text

**Step 1:** Combine Multiple Text Files into One

**NANOGPT URL:** https://git.arts.ac.uk/rfiebrink/ExploringMachineIntelligence_Spring2024/tree/main/class-5

To begin with, I collected multiple text documents and combined them into a single text file. This step ensures that all the textual data is consolidated, making it easier to process and train the model.

<img width="737" alt="Screenshot 2024-06-10 at 15 41 47" src="https://github.com/cccamelia/coding3_final_project/assets/172149092/3332ebcf-580e-48d4-b49a-cfd76c643c13">

**Step 2:** Fine-Tune nanoGPT Parameters for Improved Accuracy

- **Before adjustment**

<img width="829" alt="Screenshot 2024-06-10 at 15 28 03" src="https://github.com/cccamelia/coding3_final_project/assets/172149092/4308d3d2-fe0b-46f3-a622-2eb32cf4da21">

- **After adjustment**

<img width="858" alt="Screenshot 2024-06-10 at 14 53 35" src="https://github.com/cccamelia/coding3_final_project/assets/172149092/e02cdf9c-2dfd-411c-8781-5b6be7707a37">

## Reference

I don't use any AI in my coding, The quoted code, which I have labeled in the notebook

<img width="676" alt="Screenshot 2024-06-10 at 15 50 43" src="https://github.com/cccamelia/coding3_final_project/assets/172149092/7d191592-045e-4f26-baee-89bc76c57256">

<img width="537" alt="Screenshot 2024-06-10 at 15 56 03" src="https://github.com/cccamelia/coding3_final_project/assets/172149092/0769f67a-edc0-426c-a2ce-4468c9874386">

the sample of reference :sparkles:
